{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f990fdab-678e-4d0b-b39e-6ccb1027d0db",
   "metadata": {},
   "source": [
    "NLP (Natural Language Processing)\n",
    "Definition: Allows machines to read, understand, and generate human language. (Conceptual — no code needed here, but NLP uses libraries like NLTK, spaCy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f625dfa-4ffe-4e2e-a067-c5a3bf977c7f",
   "metadata": {},
   "source": [
    "PYPDF \n",
    "USED TO EXTRACT TEXT FROM PDF FILES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "483dd141-0e40-4e90-b370-272df4419361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b69965b8-4849-4069-92ef-b1b58c1bebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = open('US_Declaration.pdf','rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b89739d-aff2-462e-8a60-9eee75e0bce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PyPDF2.PdfReader(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32ef4194-7d8a-4ab3-bc94-7c34914beae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = reader.pages[0].extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6f7f04b-5196-40a7-8d19-35694dc3daf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Declaration of Independence\n",
      "IN CONGRESS, July 4, 1776.  \n",
      "The unanimous Declaration of the thirteen united States of America,  \n",
      "When in the Course of human events, it becomes necessary for one people to dissolve thepolitical bands which have connected them with another, and to assume among the powers of theearth, the separate and equal station to which the Laws of Nature and of Nature's God entitlethem, a decent respect to the opinions of mankind requires that they should declare the causeswhich impel them to the separation. We hold these truths to be self-evident, that all men are created equal, that they are endowed bytheir Creator with certain unalienable Rights, that among these are Life, Liberty and the pursuit\n",
      "of Happiness.— \u0014That to secure these rights, Governments are instituted among Men, derivingtheir just powers from the consent of the governed,—  \u0014That whenever any Form of Government\n",
      "becomes destructive of these ends, it is the Right of the People to alter or to abolish it, and to\n",
      "institute new Government, laying its foundation on such principles and organizing its powers in\n",
      "such form, as to them shall seem most likely to effect their Safety and Happiness. Prudence,indeed, will dictate that Governments long established should not be changed for light andtransient causes; and accordingly all experience hath shewn, that mankind are more disposed to\n",
      "suffer, while evils are sufferable, than to right themselves by abolishing the forms to which theyare accustomed. But when a long train of abuses and usurpations, pursuing invariably the same\n",
      "Object evinces a design to reduce them under absolute Despotism, it is their right, it is their duty,\n",
      "to throw off such Government, and to provide new Guards for their future securit y.— \u0014Such has\n",
      "been the patient sufferance of these Colonies; and such is now the necessity which constrainsthem to alter their former Systems of Government. The history of the present King of GreatBritain is a history of repeated injuries and usurpations, all having in direct object the\n",
      "establishment of an absolute Tyranny over these States. To prove this, let Facts be submitted to a\n",
      "candid world. \n",
      "He has refused his Assent to Laws, the most wholesome and necessary for the\n",
      "public good.He has forbidden his Governors to pass Laws of immediate and pressingimportance, unless suspended in their operation till his Assent should be obtained;and when so suspended, he has utterly neglected to attend to them.He has refused to pass other Laws for the accommodation of large districts of\n",
      "people, unless those people would relinquish the right of Representation in theLegislature, a right inestimable to them and formidable to tyrants only. He has called together legislative bodies at places unusual, uncomfortable, and distantfrom the depository of their public Records, for the sole purpose of fatiguing them into\n",
      "compliance with his measures.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b978b-36cf-421d-bba8-26e4f1301dc9",
   "metadata": {},
   "source": [
    "STEMMING\n",
    "REDUCES WORDS TO THEIR ROOT FROM (MAY NOT BE ACTUAL WORDS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae78408-3acf-488d-a639-936505001788",
   "metadata": {},
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "print(stemmer.stem(\"running\"))#run\n",
    "\n",
    "#nltk do not support in spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b29b0e6-47b2-4856-9a25-f8f08312370f",
   "metadata": {},
   "source": [
    "SNOW BALL STEMMER\n",
    "A MORE ADVANCED STEMMER(SUPPORTS MULTIPLE LANGUAGES)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52812441-4944-43eb-b2a2-131284894af0",
   "metadata": {},
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball = SnowballStemmer(\"english\")\n",
    "print(snowball.stem(\"running\")) #run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "686dc261-5b52-40fa-b31b-572e290a31e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONFUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef90a34f-4e03-4c6e-98b4-4679a38a191e",
   "metadata": {},
   "source": [
    "NLP WITH TEXT FILE \n",
    "READING TEXT FILES AND APPLYING NLP TASKS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da40dc5-3dc5-48af-b6ca-36e699c28403",
   "metadata": {},
   "source": [
    "with open('test.text','r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570a4dc8-a1b6-4fc6-9798-1b13b27e9655",
   "metadata": {},
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323e87d4-a3d6-4f34-a8da-500e80345fd6",
   "metadata": {},
   "source": [
    "FILE HANDLING\n",
    "READING/WRITING FILES USING PYTHON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee48764e-62a6-4d4c-a86a-7e45ee5f0dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('usys.txt','w') as f:\n",
    "    f.write(\"Pari\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f254130-79e1-4038-a99c-0ffc931216d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pari\n"
     ]
    }
   ],
   "source": [
    "with open('usys.txt','r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ed7579c-fb33-4851-900f-a2a922f361a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMW\n"
     ]
    }
   ],
   "source": [
    "with open(\"sumit.txt\",\"w\") as f:\n",
    "    f.write(\"BMW\")\n",
    "with open(\"sumit.txt\",\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59731ed9-142f-4588-ab12-891598453e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can write anything in the place of file name "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e88af30-6ebb-4250-9953-0231d5bfc06a",
   "metadata": {},
   "source": [
    "LEMMATIZATION\n",
    "CONVERTS WORDS TO DICTIONARY BASE FROM USING GRAMMAR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f9d40b-3606-436b-be06-984cac819de6",
   "metadata": {},
   "source": [
    "This lemmatization in nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4993ee85-bd16-44f4-bb48-8baf6db3ec19",
   "metadata": {},
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize(\"running\",pos=\"v\")) #run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d731fe09-ae17-4558-98c2-8f20b76af691",
   "metadata": {},
   "source": [
    "This lemmatizatio in spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ca9b009-7c55-402d-a100-b8b89520f554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He ➝ he\n",
      "was ➝ be\n",
      "running ➝ run\n",
      "and ➝ and\n",
      "eating ➝ eat\n",
      "while ➝ while\n",
      "others ➝ other\n",
      "were ➝ be\n",
      "playing ➝ play\n",
      ". ➝ .\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"He was running and eating while others were playing.\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text} ➝ {token.lemma_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba78bf2-e8e8-41d1-a204-c0eda34f1f71",
   "metadata": {},
   "source": [
    "NER (NAMED ENTITY RECOGNISATION)\n",
    "IDENTIFIES ENTITIES LIKE NAMES, DATES, LOCATION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea59119-0ee3-493e-8bc9-d0db5a4c0b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7feb78d-4af1-4c61-adc4-9da8a0e2a8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "Steve Jobs PERSON\n",
      "California GPE\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc =nlp(\"Apple was founded by Steve Jobs in California.\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef14e7b5-fd1b-4905-9d9f-02679535e02e",
   "metadata": {},
   "source": [
    "PHRASE MATCH\n",
    "DETECTS SPECIFIC PHRASES USING SPACY'S PhraseMatcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cad4df4e-8956-4773-b5f6-367bd712c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c924df7c-41ff-47ef-b4c5-99c6b82c874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9ed1a8c-5c9f-42a2-99f6-b5ce26e12e18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4c69a49-6d8f-4f35-8743-cfdca3fb6002",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "phrases = [\"data science\", \"machine learning\"]\n",
    "patterns = [nlp(text) for text in phrases]\n",
    "matcher.add(\"TechTerms\", patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07efcb38-b21c-443e-a74f-f9cbb6002fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I love data science and machine learning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82974f4f-2e8c-4226-b3d2-7c451fd35ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data science\n",
      "machine learning\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    print(doc[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c28bb24-9ac8-429d-916e-aad95bbd2935",
   "metadata": {},
   "source": [
    "POS (part-of-speech tagging)\n",
    "Labels each word with its grammatical type (noun, verb, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "377ac45c-b7d4-4926-8986-4c95c483c98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She PRON\n",
      "is AUX\n",
      "running VERB\n",
      "fast ADV\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"She is running fast\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff3ce2f-b755-43a6-9ee9-a999815d1501",
   "metadata": {},
   "source": [
    "Regular Expresssion \n",
    "Pattern matching in text using re module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b92f3d4b-8c4c-435b-97ba-88dce431032c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sumitkumar886091@gmail.com']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = \"My email is sumitkumar886091@gmail.com\"\n",
    "emails = re.findall(r'\\S+@\\S+', text)\n",
    "print(emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f7930-3fb7-4064-9e2c-84bfdbd3b79e",
   "metadata": {},
   "source": [
    "Spacy\n",
    "Powerful NLP Library for tasks like tokenization, NER, POS tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaff5251-0e26-43e6-96e7-f76cd873d03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP\n",
      "is\n",
      "fun\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"NLP is fun\")\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6805ca-8164-4405-b4b4-a699cc93a05a",
   "metadata": {},
   "source": [
    "Stop words\n",
    "Removes common words that add little meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4147397-1ced-4476-b16d-2e9cef881991",
   "metadata": {},
   "source": [
    "stop words are the common words in a language that don't add much meaning to a sentence - so usually remove them in text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "296a9747-ca9e-4e95-a9df-13340c2b1181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unless', 'if', 'elsewhere', 'onto', 'anyhow', '’ll', 'none', 'into', 'they', 'serious', 'him', 'really', 'somehow', 'does', 'seeming', 'has', 'but', 'below', 'becomes', 'eleven', 'many', 'thru', 'wherein', 'quite', 'there', 'whom', 'were', 'something', 'formerly', 'whither', 'is', 'much', 'indeed', 'whoever', 'alone', 'however', 'well', 'whose', 'everything', 'before', 'noone', 'no', 'besides', 'afterwards', 'during', 'moreover', 'yours', 'was', 'my', 'every', 'see', 'only', 'am', 'here', 'up', 'became', 'did', 'others', 'just', 'than', 'various', 'back', 'too', 'sometimes', 'ours', 'either', 'your', 'beforehand', 'within', 'another', 'anyway', 'myself', 'although', 'itself', 'ourselves', 'been', 'per', 'never', 'whether', 'against', 'not', 'nine', 'he', 'herein', 'between', 'so', 'get', 'himself', 'their', 'down', 'third', 'twelve', 'through', '‘s', 'seems', 'hers', \"'ve\", 'could', 'therein', 'that', 'own', 'being', 'hereby', 'keep', 'around', 'it', 'without', 'for', 'have', 'show', 'further', 'out', 'hereupon', 'make', 'whence', 'our', 'four', 'upon', 'until', 'will', 'amount', 'her', 'under', 'bottom', 'say', 'used', 'enough', 'whereas', 'yet', 'though', 'yourself', 'nevertheless', 'top', 'do', 'eight', 'nobody', '‘d', 'whole', 'seem', 'due', 'from', 'side', 'whenever', 'move', 'becoming', 'some', 'who', 'of', 'thereby', 'or', 'done', 'mine', 'more', 'take', 'first', 'anything', 'those', 'can', 'these', 'over', 'beside', 'full', 'herself', 'n‘t', 'whereafter', 'in', \"'ll\", 'thereafter', \"'m\", 'twenty', 'already', 'regarding', 'neither', 'please', 'at', 'along', 'anywhere', '’ve', 'and', 'themselves', \"'d\", 'them', 'we', 'two', 'she', 'any', 'several', 'everywhere', 're', 'behind', 'where', 'anyone', 'to', 'me', 'n’t', '‘re', 'why', 'empty', 'after', 'what', 'often', 'off', 'somewhere', \"'re\", 'then', 'toward', '’s', 'one', 'via', 'also', 'once', 'almost', 'rather', 'most', 'again', 'throughout', 'less', '’m', 'everyone', 'perhaps', 'above', 'former', 'whereby', 'fifteen', 'while', 'except', 'thus', 'its', 'sixty', 'thence', 'how', 'cannot', 'a', 'seemed', 'with', 'very', 'whatever', 'each', 'doing', 'mostly', 'least', 'which', 'all', 'on', 'give', 'forty', 'still', 'across', 'made', 'name', 'i', \"n't\", 'must', 'put', 'might', 'hundred', '‘m', 'namely', 'when', 'latter', 'someone', 'otherwise', 'as', 'by', 'would', 'should', 'had', 'since', 'same', 'ever', 'his', 'ten', '‘ve', 'hence', 'an', 'go', 'five', 'among', 'using', 'nor', 'nowhere', 'even', 'towards', 'else', 'become', 'six', 'whereupon', 'nothing', 'amongst', 'fifty', 'are', 'us', 'part', 'therefore', \"'s\", 'may', 'next', 'front', 'this', 'now', 'wherever', 'such', '’re', 'you', 'beyond', 'be', 'the', 'together', 'ca', 'sometime', 'always', 'call', 'yourselves', 'because', 'meanwhile', 'last', 'few', 'thereupon', 'other', 'both', '’d', 'hereafter', 'three', 'latterly', '‘ll', 'about'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61a66952-f31e-4e01-9ee2-39261d5d4476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d662604-c609-4b9f-9598-d195e48d5d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['both'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a1e41d3-bba9-4162-85bd-f09aea2a1ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words.add('btw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e710c0de-defc-4668-bf40-32d8f9289713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16c4afd5-9401-4e54-af69-8a0a92655db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words.remove('you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "872e034f-2b36-42fe-b87c-dd25fd6d2e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e10592-dc61-4ac5-a481-82e2b5926dd9",
   "metadata": {},
   "source": [
    "Tokeniztion\n",
    "spliting text into words or sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01efa127-b1d0-4193-baa9-6de45d21a39c",
   "metadata": {},
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "print(word_tokenize(\"I love NLP.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e99543-f9a5-4475-b414-1da184c83e3a",
   "metadata": {},
   "source": [
    "vocabulary\n",
    "unique set of words in a text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51df1158-4734-44d6-9828-137403c97fde",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "text = \"NLP is fun and NLP is powerful\"\n",
    "words = set(word_tokenize(text.lower))\n",
    "print(words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
